{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import overpy\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import branca.colormap as cm \n",
    "\n",
    "\n",
    "useragent = 'Your website or application name/your contact'\n",
    "headers = {\n",
    "    'Connection': 'keep-alive',\n",
    "    'sec-ch-ua': '\"Google Chrome 80\"',\n",
    "    'Accept': '*/*',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'User-Agent': useragent,\n",
    "    'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n",
    "    'Origin': 'https://overpass-turbo.eu',\n",
    "    'Sec-Fetch-Site': 'cross-site',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Referer': 'https://overpass-turbo.eu/',\n",
    "    'Accept-Language': '',\n",
    "    'dnt': '1',\n",
    "}\n",
    "\n",
    "COUNTIES_PATH = 'data/CA_Counties/CA_Counties_TIGER2016.shp'\n",
    "POP_DENSITY_DIR = 'popDensity/'\n",
    "OSM_QUERY = POP_DENSITY_DIR + 'query.osm'\n",
    "MAP_DIR = POP_DENSITY_DIR + 'maps/'\n",
    "PRED_MAP_DIR = POP_DENSITY_DIR + 'pred_maps/'\n",
    "FLU_BY_REGION_DIR = 'flu_region/'\n",
    "FLU_BY_DATES_DIR = f\"{FLU_BY_REGION_DIR}flu_by_dates\"\n",
    "FLU_BY_DATES_PRED_DIR = f\"{FLU_BY_REGION_DIR}pred_by_dates\"\n",
    "\n",
    "assert( os.path.isdir( FLU_BY_REGION_DIR ) )\n",
    "assert( os.path.isdir( FLU_BY_DATES_DIR ) )\n",
    "assert( os.path.isdir( FLU_BY_DATES_PRED_DIR ) )\n",
    "\n",
    "assert( os.path.isfile( COUNTIES_PATH ) )\n",
    "if not os.path.isdir( POP_DENSITY_DIR ):\n",
    "    os.mkdir( POP_DENSITY_DIR )\n",
    "if not os.path.isdir( MAP_DIR ):\n",
    "    os.mkdir( MAP_DIR )\n",
    "if not os.path.isdir( PRED_MAP_DIR ):\n",
    "    os.mkdir( PRED_MAP_DIR )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the OSM data for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\anaconda3\\lib\\site-packages\\pyproj\\crs\\crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    }
   ],
   "source": [
    "counties = gpd.read_file( COUNTIES_PATH )\n",
    "counties = counties.to_crs({'init': 'epsg:4326'})\n",
    "bbox = counties.total_bounds\n",
    "# tighter bounding box than the box above\n",
    "calBounds = \"32.6856199 -114.2028809 34.5246615 -113.9941406 39.0447860 -119.9926758 41.9839943 -119.9487305 41.9676592 -125.5737305 40.2459915 -124.9365234 37.3526928 -124.2993164 32.6578757 -121.3549805 32.6578757 -114.2358398 32.6856199 -114.2028809\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = f\"\"\"\n",
    "[out:xml] [timeout:50];\n",
    "(\n",
    "    nwr[\"place\"](poly:\"{calBounds}\" );\n",
    ");\n",
    "out body;\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "  'data' : query \n",
    "}\n",
    "# call the api to get the query\n",
    "response = requests.post( 'https://overpass-api.de/api/interpreter', headers=headers, data=data )\n",
    "# write the response to file for reusing\n",
    "with open( 'popDensity/query.osm', 'w' ) as f:\n",
    "  f.write( response.text )\n",
    "  f.close()\n",
    "assert( os.path.isfile( OSM_QUERY ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the resulting api call\n",
    "api = overpy.Overpass()\n",
    "result = api.parse_xml( response.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "# make the geojson for each of the nodes that have a population.\n",
    "for i in result.nodes:\n",
    "  if( i.tags.get('place') != 'state' ):\n",
    "    if( 'population' in i.tags ):\n",
    "      pop = i.tags.get( 'population', -1 ) # note pop is a string by default\n",
    "      if pop != -1:\n",
    "        pop = int( pop )\n",
    "        nodes.append( {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [ i.lon, i.lat ],\n",
    "        },\n",
    "        \"properties\": {\n",
    "          \"population\" : i.tags.get( 'population', 0 )\n",
    "        }\n",
    "});\n",
    "  \n",
    "gdfNodes = gpd.GeoDataFrame.from_features([node for node in nodes], crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeMap( caTotalILI, min, max, csvFile, outputDir ):\n",
    "  output = outputDir + os.path.splitext(csvFile)[0] + \".html\"\n",
    "  # create a folium map centered on the bounding box of cali\n",
    "  m = folium.Map( location=[ ( bbox[3] + bbox[1] ) / 2, ( bbox[0] + bbox[2] ) / 2 ], zoom_start=7, prefer_canvas=True )\n",
    "\n",
    "  #color scale\n",
    "  linear = cm.linear.Reds_09.scale( min, max )\n",
    "  linear.caption = 'Total Influenza Like Illness (ILI)'\n",
    "  m.add_child( linear )\n",
    "  def styleFn( feature ):\n",
    "      \"\"\"Function to apply color based on Total_ILI value.\"\"\"\n",
    "      Total_ILI = feature['properties']['Total_ILI']\n",
    "      return {\n",
    "          'fillColor': linear( Total_ILI ),\n",
    "          'color': 'black',\n",
    "          'weight': 2,\n",
    "          'fillOpacity': .5\n",
    "      }\n",
    "\n",
    "  # add the counties shapefile\n",
    "  geojson = json.loads( caTotalILI.to_json() )\n",
    "  tooltip = folium.GeoJsonTooltip( fields=['Total_ILI'] )\n",
    "\n",
    "  # add the points for the heatmap\n",
    "  data = [ [ point.xy[1][0], point.xy[0][0], int( pop ) ] for point, pop in zip( gdfNodes.geometry, gdfNodes['population'] ) ]\n",
    "\n",
    "  # create feature group\n",
    "  featILI = folium.FeatureGroup( name=\"Total ILI\" ).add_to( m )\n",
    "  featHeat = folium.FeatureGroup( name=\"Population Density\" ).add_to( m )\n",
    "\n",
    "  #add the total ILI to the feature group\n",
    "  folium.GeoJson( geojson, tooltip=tooltip, style_function=styleFn ).add_to( featILI )\n",
    "  # create a HeatMap layer using the population data\n",
    "  HeatMap( data, overlay=True, control=True ).add_to( featHeat )\n",
    "  # add the layer control to the map\n",
    "  folium.LayerControl().add_to( m )\n",
    "\n",
    "  # display the map\n",
    "  m.save( output )  # Save the heatmap as an HTML file\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate all the file for all the actual csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFiles = [ filename for filename in os.listdir( FLU_BY_DATES_DIR ) if filename.endswith( \".csv\" ) ]\n",
    "ca = gpd.read_file( COUNTIES_PATH )\n",
    "\n",
    "for csvFile in csvFiles:\n",
    "# if True:\n",
    "  csvPath = os.path.join( FLU_BY_DATES_DIR, csvFile )\n",
    "  df = pd.read_csv( csvPath )\n",
    "  # Calculate the maximum and minimum values in the \"Total_ILI\" column\n",
    "  max_value = df[\"Total_ILI\"].max()\n",
    "  min_value = df[\"Total_ILI\"].min()\n",
    "  \n",
    "  #for pred stuff only \n",
    "  ca[\"COUNTYNS\"] = ca[\"COUNTYNS\"].astype(int)\n",
    "  \n",
    "  #Merge files\n",
    "  mapf = \"COUNTYNS\"\n",
    "  statf = \"region\"\n",
    "  df = df[ ['Total_ILI', 'region' ] ]\n",
    "  # df['region'] = df['region'].astype( str )\n",
    "  caTotalILI = ca.merge( df, left_on=mapf, right_on=statf )\n",
    "  caTotalILI = caTotalILI.to_crs( 'epsg:4326' )\n",
    "  makeMap( caTotalILI, min_value, max_value, csvFile, MAP_DIR )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate all the csv for the pred maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFiles = [ filename for filename in os.listdir( FLU_BY_DATES_PRED_DIR ) if filename.endswith( \".csv\" ) ]\n",
    "ca = gpd.read_file( COUNTIES_PATH )\n",
    "\n",
    "for csvFile in csvFiles:\n",
    "# if True:\n",
    "  csvPath = os.path.join( FLU_BY_DATES_PRED_DIR, csvFile )\n",
    "  df = pd.read_csv( csvPath )\n",
    "  # Calculate the maximum and minimum values in the \"Total_ILI\" column\n",
    "  max_value = df[\"Total_ILI\"].max()\n",
    "  min_value = df[\"Total_ILI\"].min()\n",
    "  \n",
    "  #for pred stuff only \n",
    "  ca[\"COUNTYNS\"] = ca[\"COUNTYNS\"].astype(int)\n",
    "  \n",
    "  #Merge files\n",
    "  mapf = \"COUNTYNS\"\n",
    "  statf = \"region\"\n",
    "  df = df[ ['Total_ILI', 'region' ] ]\n",
    "  # df['region'] = df['region'].astype( str )\n",
    "  caTotalILI = ca.merge( df, left_on=mapf, right_on=statf )\n",
    "  caTotalILI = caTotalILI.to_crs( 'epsg:4326' )\n",
    "  makeMap( caTotalILI, min_value, max_value, csvFile, PRED_MAP_DIR )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
